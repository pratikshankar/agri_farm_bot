{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader,CSVLoader,TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01231345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pratikshankar/code/genai_projects/agri_farm_bot/research'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6e2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d091db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agr=pd.read_csv('Data/agriculture_mock_data.csv')\n",
    "df_dairy=pd.read_csv('Data/dairy_mock_data.csv')\n",
    "df=pd.concat([df_agr, df_dairy], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64fa28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ca747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agr=pd.read_csv('Data/mock_agriculture_farm_10yrs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agr.groupby('Year')['Yield_quintals'].mean().plot(title='Average Yield per Year', xlabel='Year', ylabel='Yield')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1def11a",
   "metadata": {},
   "source": [
    "### chunking and vectorizing the knowledge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ddbfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader_pdf=DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents_pdf = loader_pdf.load()\n",
    "\n",
    "    loader_csv=DirectoryLoader(data, glob=\"*.csv\", loader_cls=CSVLoader)\n",
    "    documents_csv = loader_csv.load()\n",
    "    \n",
    "\n",
    "    loader_txt=DirectoryLoader(data, glob=\"*.txt\",loader_cls=TextLoader)\n",
    "    documents_txt = loader_txt.load()\n",
    "\n",
    "    documents = documents_csv+documents_pdf+documents_txt\n",
    "\n",
    "\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d086c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data=\"Data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04fc5ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV File Data/mock_data_farm_2 years.txt\n"
     ]
    }
   ],
   "source": [
    "lst=[]\n",
    "for d in extracted_data:\n",
    "    if d.metadata['source'].endswith('.txt'):\n",
    "        if d.metadata['source'] not in lst:\n",
    "            lst.append(d.metadata['source'])\n",
    "            print(\"CSV File\",d.metadata['source'])\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f00519b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "        length_function=len,\n",
    "        \n",
    "    )\n",
    "    texts = text_splitter.split_documents(extracted_data)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41352141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 1000\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data=extracted_data)\n",
    "print(f\"Total number of chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98bcb037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')#'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20d8fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6104e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embed=embeddings.embed_query(\"What is the capital of France?\")\n",
    "print(test_embed)\n",
    "print(len(test_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8805ef88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'dotproduct',\n",
       " 'namespaces': {'': {'vector_count': 17104}},\n",
       " 'total_vector_count': 17104,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "from pinecone import Pinecone\n",
    "index_name=\"agri-rag-bot\"\n",
    "\n",
    "\n",
    "pc=Pinecone(api_key=PINECONE_API_KEY)\n",
    "from pinecone import ServerlessSpec\n",
    "if not pc.has_index(name=index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric='dotproduct',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "index=pc.Index(name=index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "463ed039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeding with embeddings\n",
      "Embeddings generated\n",
      "Vectors prepared for Pinecone\n",
      "Uploading batch 1 of 26\n",
      "Uploading batch 2 of 26\n",
      "Uploading batch 3 of 26\n",
      "Uploading batch 4 of 26\n",
      "Uploading batch 5 of 26\n",
      "Uploading batch 6 of 26\n",
      "Uploading batch 7 of 26\n",
      "Uploading batch 8 of 26\n",
      "Uploading batch 9 of 26\n",
      "Uploading batch 10 of 26\n",
      "Uploading batch 11 of 26\n",
      "Uploading batch 12 of 26\n",
      "Uploading batch 13 of 26\n",
      "Uploading batch 14 of 26\n",
      "Uploading batch 15 of 26\n",
      "Uploading batch 16 of 26\n",
      "Uploading batch 17 of 26\n",
      "Uploading batch 18 of 26\n",
      "Uploading batch 19 of 26\n",
      "Uploading batch 20 of 26\n",
      "Uploading batch 21 of 26\n",
      "Uploading batch 22 of 26\n",
      "Uploading batch 23 of 26\n",
      "Uploading batch 24 of 26\n",
      "Uploading batch 25 of 26\n",
      "✅ All chunks uploaded safely without exceeding Pinecone size limits.\n"
     ]
    }
   ],
   "source": [
    "documents = load_pdf_file('Data/')\n",
    "text_chunks = text_split(documents)\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "print(\"Proceeding with embeddings\")\n",
    "\n",
    "embedded_vectors = embeddings.embed_documents([chunk.page_content for chunk in text_chunks])\n",
    "print(\"Embeddings generated\")\n",
    "def clean_metadata(meta: dict) -> dict:\n",
    "    return {\n",
    "        \"text\": meta.get(\"text\", \"\")[:500],\n",
    "        \"source\": meta.get(\"source\", \"unknown\"),\n",
    "        \"page\": meta.get(\"page\", -1) if meta.get(\"page\") is not None else -1\n",
    "    }\n",
    "# Prepare vectors for Pinecone\n",
    "vectors = []\n",
    "for i, (text_chunk, vector) in enumerate(zip(text_chunks, embedded_vectors)):\n",
    "    \n",
    "        metadata= {\n",
    "            \"text\": text_chunk.page_content[:500],  # Keep metadata light!\n",
    "            \"source\": text_chunk.metadata.get(\"source\"),\n",
    "            \"page\": text_chunk.metadata.get(\"page\")\n",
    "        }\n",
    "        vectors.append({\n",
    "        \"id\": f\"chunk-{i}\",\n",
    "        \"values\": vector,\n",
    "        \"metadata\": clean_metadata(metadata)\n",
    "    })\n",
    "    \n",
    "print(\"Vectors prepared for Pinecone\")\n",
    "# === Batch Upload Safely ===\n",
    "def batch_upsert(index, vectors, batch_size=50):\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        print(f\"Uploading batch {i // batch_size + 1} of {len(vectors) // batch_size + 1}\")\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        index.upsert(vectors=batch)\n",
    "# index_name=\"agri-rag-bot\"\n",
    "batch_upsert(index, vectors, batch_size=40)  # 40 is a safe number for 768 dim\n",
    "print(\"✅ All chunks uploaded safely without exceeding Pinecone size limits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0da47184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing docsearch with the existing index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch=PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bf0f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver=docsearch.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 100})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f695937",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is my farm's yeild per year look like?\"\n",
    "retriver.invoke(input=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffce3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### initilizing the LLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    temperature=0.8,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80223143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bacillus anthracis is sensitive to a number of antibiotics and treatment of animals during the early stages of the disease is likely to be successful, although severely ailing animals are unlikely to recover.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "# from langchain.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# system_prompt=(\n",
    "#     \"You are an aggriculture expert.Answer teh farmer's query based on the data provided to you.You have farm specific history and the knowledge texts.Answer Concisely so that the farmer can understand.Also mention the source of the result{context} \"\n",
    "# )\n",
    "system_prompt = (\"\"\"\n",
    "You are AgriBot, a multilingual expert assistant trained on detailed agricultural and dairy farm records. \n",
    "You have access to embedded farm data including crop cultivation logs, climate records, fertilizer usage, cow health records, milk production logs, and disease history from PDFs and CSV files.\n",
    "\n",
    "Your job is to:\n",
    "1. Analyze this farm-specific knowledge base.\n",
    "2. Answer user questions accurately using only the information from these documents.\n",
    "3. If the query is a summarization request, provide concise summaries based on the relevant data.\n",
    "4. If the answer is not present in the data, respond with \"The required information is not available in the farm documents.\"\n",
    "5. Support both English and local language queries (Kannada, Hindi, Marathi, etc.) using multilingual understanding.\n",
    "\n",
    "Always be concise, clear, and factual{context}.\n",
    "\"\"\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriver, question_answer_chain)\n",
    "\n",
    "# Query\n",
    "query = \"how to treat brucellosis?\"\n",
    "response = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c09d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "supported_langs = {\n",
    "    \"hi\": \"hindi\",\n",
    "    \"mr\": \"marathi\",\n",
    "    \"kn\": \"kannada\",\n",
    "    \"en\": \"english\"\n",
    "}\n",
    "\n",
    "def detect_and_translate_to_english(text):\n",
    "    return GoogleTranslator(source='auto', target='english').translate(text)\n",
    "\n",
    "def translate_from_english(text, target_lang_code=\"hi\"):\n",
    "    target_lang = supported_langs.get(target_lang_code, \"english\")\n",
    "    return GoogleTranslator(source='english', target=target_lang).translate(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f471cb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "दूध में वसा की मात्रा बढ़ाने के कुछ उपाय इस प्रकार हैं:\n",
      "\n",
      "* **संतुलित आहार:** गाय को उचित मात्रा में हरा चारा, सूखा चारा और दाना खिलाएं। आहार में फाइबर की मात्रा पर्याप्त होनी चाहिए।\n",
      "* **वसा युक्त आहार:** आहार में तेल बीज, सोयाबीन, सूरजमुखी के बीज या अलसी जैसे वसा युक्त खाद्य पदार्थों को शामिल करें।\n",
      "* **पानी:** गाय को पर्याप्त मात्रा में पानी पिलाएं।\n",
      "* **स्वस्थ रखें:** गाय को बीमारियों से बचाएं, खासकर मास्टिटिस से, जो दूध की गुणवत्ता को प्रभावित कर सकती है।\n",
      "* **नियमित दूध दुहना:** गाय को नियमित अंतराल पर पूरी तरह से दुहना चाहिए। अपूर्ण दुहने से दूध में वसा की मात्रा कम हो सकती है।\n",
      "* **दुहने का समय:** दूध में वसा की मात्रा दुहने की प्रक्रिया के दौरान लगातार बढ़ती है। पहले निकाले गए दूध में केवल 1-2% वसा हो सकती है, जबकि अंत में निकाले गए दूध में 5-10% वसा हो सकती है।\n",
      "\n",
      "इन उपायों को अपनाकर आप अपनी गाय के दूध में वसा की मात्रा बढ़ा सकते हैं।\n",
      "\n",
      "**स्रोत:**\n",
      "\n",
      "*   पशुपालन विशेषज्ञ\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "# from langchain.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google.cloud import translate_v2 as translate\n",
    "\n",
    "\n",
    "system_prompt=(\n",
    "    \"You are an aggriculture expert.Answer teh farmer's query based on the data provided to you.You have farm specific history and the knowledge texts.Answer Concisely so that the farmer can understand.Also mention the source of the result{context} \"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriver, question_answer_chain)\n",
    "\n",
    "# Query\n",
    "query = \"दूध में फैट बढ़ाने के उपाय बताइए?\"\n",
    "\n",
    "\n",
    "\n",
    "response = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74a339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaidemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
